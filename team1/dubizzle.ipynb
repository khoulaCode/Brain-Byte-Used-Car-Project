{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b07f1915",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import time\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# ---------- Selenium setup ----------\n",
    "import undetected_chromedriver as uc\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "# ------------ Config -------------\n",
    "BASE_URL = \"https://www.dubizzle.com.om\"\n",
    "URL_TEMPLATE = BASE_URL + \"/en/vehicles/cars-for-sale/q-cars-for-sale/?page={}\"\n",
    "MAX_PAGES = 199                    # increase if needed\n",
    "RENDER_TIMEOUT = 20              # seconds to wait for listings to appear\n",
    "DETAIL_TIMEOUT = 15              # seconds to wait for detail content\n",
    "POLITE_DELAY = 2                 # seconds between pages / requests\n",
    "\n",
    "# Data storage\n",
    "dubizzle_cars = {\n",
    "    'car_title': [],\n",
    "    'location': [],\n",
    "    'year': [],\n",
    "    'price': [],\n",
    "    'kilometers': [],\n",
    "    'transmission_type': [],\n",
    "    'number_of_doors': [],\n",
    "    'source': [],   # GCC, US, etc.\n",
    "    'model': [],\n",
    "    'color': [],\n",
    "    'contact_number': [],\n",
    "}\n",
    "\n",
    "# ---------- Utilities ----------\n",
    "def norm(s: str) -> str:\n",
    "    return re.sub(r'\\s+', ' ', s or '').strip()\n",
    "\n",
    "def get_value_by_label(container, label_keywords, label_tag='span'):\n",
    "    \"\"\"\n",
    "    Look for a container where the 1st <span> is label ('Transmission') and 2nd <span> is value ('Automatic').\n",
    "    \"\"\"\n",
    "    for box in container.find_all(['div', 'li', 'section', 'article'], recursive=True):\n",
    "        spans = box.find_all('span', recursive=False)\n",
    "        if len(spans) < 2:\n",
    "            spans = box.find_all('span', recursive=True)\n",
    "\n",
    "        if len(spans) >= 2:\n",
    "            label_text = norm(spans[0].get_text()).lower()\n",
    "            for kw in label_keywords:\n",
    "                if kw in label_text:\n",
    "                    value_text = norm(spans[1].get_text())\n",
    "                    if value_text:\n",
    "                        return value_text\n",
    "    return None\n",
    "\n",
    "# ---------- Field-specific extractors ----------\n",
    "def extract_kilometers(listing):\n",
    "    \"\"\"\n",
    "    Extract kilometers value using several strategies.\n",
    "    \"\"\"\n",
    "    km_value = \"N/A\"\n",
    "\n",
    "    # A) Generic label -> value\n",
    "    generic = get_value_by_label(listing, ['kilometer', 'km', 'mileage'])\n",
    "    if generic:\n",
    "        return generic\n",
    "\n",
    "    # B) Known class pattern (harmless if classes differ)\n",
    "    for block in listing.select('div._948d9e0a'):\n",
    "        spans = block.select('span._8206696c')\n",
    "        if len(spans) >= 2 and spans[0].get_text(strip=True).lower() in [\"kilometers\", \"km\", \"mileage\"]:\n",
    "            km_value = spans[1].get_text(strip=True)\n",
    "            break\n",
    "\n",
    "    # C) Any span with \"km\" or \"kilometers\"\n",
    "    if km_value == \"N/A\":\n",
    "        km_spans = listing.find_all('span', string=re.compile(r'\\d+.*km|kilometers', re.IGNORECASE))\n",
    "        for span in km_spans:\n",
    "            km_text = span.get_text(strip=True)\n",
    "            km_match = re.search(r'(\\d[\\d,]*)', km_text)\n",
    "            if km_match:\n",
    "                km_value = km_match.group(1)\n",
    "                break\n",
    "\n",
    "    # D) aria-label\n",
    "    if km_value == \"N/A\":\n",
    "        km_tag = listing.find('span', attrs={'aria-label': re.compile(r'kilometer', re.IGNORECASE)})\n",
    "        if km_tag:\n",
    "            km_span = km_tag.find('span')\n",
    "            if km_span:\n",
    "                km_value = km_span.text.strip()\n",
    "\n",
    "    # E) Final free regex scan\n",
    "    if km_value == \"N/A\":\n",
    "        for span in listing.find_all('span'):\n",
    "            text = span.get_text(strip=True)\n",
    "            if re.search(r'\\d[\\d,]*\\s*(km|kilometers)', text, re.IGNORECASE):\n",
    "                km_match = re.search(r'(\\d[\\d,]*)', text)\n",
    "                if km_match:\n",
    "                    km_value = km_match.group(1)\n",
    "                    break\n",
    "\n",
    "    return km_value\n",
    "\n",
    "def extract_transmission(listing):\n",
    "    \"\"\"\n",
    "    Strict rule you wanted:\n",
    "    If FIRST <span> == 'Transmission' (or 'Transmission Type'), return SECOND <span>.\n",
    "    \"\"\"\n",
    "    for box in listing.find_all('div'):\n",
    "        spans = box.find_all('span', recursive=False)\n",
    "        if len(spans) < 2:\n",
    "            spans = box.find_all('span', recursive=True)\n",
    "        if len(spans) >= 2:\n",
    "            label = norm(spans[0].get_text()).lower()\n",
    "            if label in ('transmission', 'transmission type'):\n",
    "                return norm(spans[1].get_text())\n",
    "    return \"N/A\"\n",
    "\n",
    "def extract_doors(listing):\n",
    "    \"\"\"\n",
    "    Extract number of doors.\n",
    "    Priority:\n",
    "      1) Class-based: <div class=\"_9a8eacd9\"><span>Number of doors</span><span>4/5</span></div>\n",
    "      2) Generic 'first span = label / second = value'\n",
    "      3) aria-label fallback\n",
    "    \"\"\"\n",
    "    # --- 1) Class-based extraction (your provided class) ---\n",
    "    door_block = listing.find('div', class_='_9a8eacd9')\n",
    "    if door_block:\n",
    "        spans = door_block.find_all('span')\n",
    "        if len(spans) >= 2:\n",
    "            return norm(spans[1].get_text())\n",
    "\n",
    "    # --- 2) Generic rule ---\n",
    "    for box in listing.find_all('div'):\n",
    "        spans = box.find_all('span', recursive=False)\n",
    "        if len(spans) < 2:\n",
    "            spans = box.find_all('span', recursive=True)\n",
    "        if len(spans) >= 2 and norm(spans[0].get_text()).lower() in ['number of doors', 'doors']:\n",
    "            return norm(spans[1].get_text())\n",
    "\n",
    "    # --- 3) Fallback: aria-label ---\n",
    "    tag = listing.find('span', attrs={'aria-label': re.compile(r'door', re.IGNORECASE)})\n",
    "    if tag:\n",
    "        value = tag.find('span')\n",
    "        if value:\n",
    "            return norm(value.get_text())\n",
    "\n",
    "    return \"N/A\"\n",
    "\n",
    "def extract_source(container):\n",
    "    \"\"\"\n",
    "    Extract Source (e.g., GCC, US) from:\n",
    "      <div class=\"_9a8eacd9\"><span>Source</span><span>GCC</span></div>\n",
    "    Falls back to generic label->value search.\n",
    "    Works for either a listing card or a detail page soup.\n",
    "    \"\"\"\n",
    "    # 1) Class-based block\n",
    "    src_block = container.find('div', class_='_9a8eacd9')\n",
    "    if src_block:\n",
    "        spans = src_block.find_all('span')\n",
    "        if len(spans) >= 2 and norm(spans[0].get_text()).lower() == 'source':\n",
    "            return norm(spans[1].get_text())\n",
    "\n",
    "    # 2) Generic fallback (covers other wordings too)\n",
    "    generic = get_value_by_label(container, ['source', 'regional specs', 'regional specification'])\n",
    "    if generic:\n",
    "        return generic\n",
    "\n",
    "    return \"N/A\"\n",
    "\n",
    "# ---------- Selenium helpers ----------\n",
    "def make_driver():\n",
    "    opts = uc.ChromeOptions()\n",
    "    opts.add_argument(\"--headless=new\")\n",
    "    opts.add_argument(\"--disable-gpu\")\n",
    "    opts.add_argument(\"--window-size=1366,768\")\n",
    "    opts.add_argument(\"--no-sandbox\")\n",
    "    opts.add_argument(\"--disable-dev-shm-usage\")\n",
    "    # Same UA helps reduce bot checks\n",
    "    opts.add_argument(\"--user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) \"\n",
    "                      \"AppleWebKit/537.36 (KHTML, like Gecko) \"\n",
    "                      \"Chrome/91.0.4472.124 Safari/537.36\")\n",
    "    return uc.Chrome(options=opts)\n",
    "\n",
    "def get_rendered_soup(driver, url, wait_selector=\"li[aria-label='Listing'], div[class*='listing'], article\"):\n",
    "    driver.get(url)\n",
    "    driver.execute_script(\"window.scrollTo(0, 300);\")\n",
    "    try:\n",
    "        WebDriverWait(driver, RENDER_TIMEOUT).until(\n",
    "            EC.presence_of_element_located((By.CSS_SELECTOR, wait_selector))\n",
    "        )\n",
    "    except TimeoutException:\n",
    "        pass\n",
    "    return BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "def get_detail_soup(driver, url):\n",
    "    driver.get(url)\n",
    "    try:\n",
    "        WebDriverWait(driver, DETAIL_TIMEOUT).until(\n",
    "            EC.any_of(\n",
    "                EC.presence_of_element_located((By.CSS_SELECTOR, \"h1, h2\")),\n",
    "                EC.presence_of_element_located((By.CSS_SELECTOR, \"div, section\"))\n",
    "            )\n",
    "        )\n",
    "    except TimeoutException:\n",
    "        pass\n",
    "    driver.execute_script(\"window.scrollTo(0, 600);\")\n",
    "    time.sleep(0.5)\n",
    "    return BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "# ---------- Main scrape ----------\n",
    "def main():\n",
    "    driver = make_driver()\n",
    "\n",
    "    current_page = 1\n",
    "    while True:\n",
    "        url = URL_TEMPLATE.format(current_page)\n",
    "        print(f\"Fetching page {current_page}: {url}\")\n",
    "\n",
    "        soup = get_rendered_soup(driver, url)\n",
    "\n",
    "        listing_selectors = [\n",
    "            ('li', {\"aria-label\": \"Listing\"}),\n",
    "            ('div', {\"class\": re.compile(r'listing', re.IGNORECASE)}),\n",
    "            ('article', {}),\n",
    "            ('div', {\"class\": re.compile(r'item|card|post', re.IGNORECASE)}),\n",
    "            ('li', {\"class\": re.compile(r'listing|item|card', re.IGNORECASE)})\n",
    "        ]\n",
    "\n",
    "        listings = []\n",
    "        for tag, attrs in listing_selectors:\n",
    "            potential = soup.find_all(tag, attrs) if attrs else soup.find_all(tag)\n",
    "            print(f\"Found {len(potential)} with selector: {tag} {attrs}\")\n",
    "            if potential:\n",
    "                listings = potential\n",
    "                print(f\"Using selector: {tag} {attrs}\")\n",
    "                break\n",
    "\n",
    "        if not listings:\n",
    "            print(f\":x: No listings found on page {current_page}. Saved HTML for inspection.\")\n",
    "            with open(f\"debug_page_{current_page}.html\", \"w\", encoding=\"utf-8\") as f:\n",
    "                f.write(soup.prettify())\n",
    "            break\n",
    "\n",
    "        print(f\":white_check_mark: {len(listings)} listings found\")\n",
    "\n",
    "        for listing in listings:\n",
    "            # Title\n",
    "            title_tag = listing.find('h2') or listing.find('h3')\n",
    "            title = norm(title_tag.get_text()) if title_tag else \"N/A\"\n",
    "\n",
    "            # Location (best-effort)\n",
    "            loc_tag = listing.find('span', class_=re.compile(r'f7d5e47e')) \\\n",
    "                   or listing.find('span', string=re.compile(r',\\s*Muscat|AL', re.IGNORECASE))\n",
    "            location = norm(loc_tag.get_text()) if loc_tag else \"N/A\"\n",
    "\n",
    "            # Year\n",
    "            year_tag = listing.find('span', attrs={'aria-label': re.compile(r'year', re.IGNORECASE)})\n",
    "            year_span = year_tag.find('span') if year_tag else None\n",
    "            year = norm(year_span.get_text()) if year_span else \"N/A\"\n",
    "\n",
    "            # Price\n",
    "            price_tag = listing.find('span', class_=re.compile(r'ddc1b288')) \\\n",
    "                        or listing.find('span', string=re.compile(r'OMR|\\d'))\n",
    "            price = norm(price_tag.get_text()) if price_tag else \"N/A\"\n",
    "\n",
    "            # Kilometers / Transmission / Doors\n",
    "            kilometers = extract_kilometers(listing)\n",
    "            transmission = extract_transmission(listing)\n",
    "            doors = extract_doors(listing)\n",
    "\n",
    "            # Detail URL\n",
    "            link_tag = listing.find('a', href=True)\n",
    "            detail_url = None\n",
    "            if link_tag:\n",
    "                href = link_tag['href']\n",
    "                detail_url = BASE_URL + href if href.startswith('/') else href\n",
    "\n",
    "            # Defaults\n",
    "            model, color, source, contact_number = \"N/A\", \"N/A\", \"N/A\", \"N/A\"\n",
    "\n",
    "            # Detail page for more info\n",
    "            if detail_url:\n",
    "                try:\n",
    "                    detail_soup = get_detail_soup(driver, detail_url)\n",
    "\n",
    "                    def get_detail(label_list):\n",
    "                        return get_value_by_label(detail_soup, [l.lower() for l in label_list])\n",
    "\n",
    "                    model_val = get_detail(['Model'])\n",
    "                    if model_val: model = model_val\n",
    "\n",
    "                    color_val = get_detail(['Color'])\n",
    "                    if color_val: color = color_val\n",
    "\n",
    "                    # --- Source (class-based first, then generic) ---\n",
    "                    src_val = extract_source(detail_soup)\n",
    "                    if src_val != \"N/A\":\n",
    "                        source = src_val\n",
    "                    else:\n",
    "                        source_val = get_detail(['Source', 'Regional Specs', 'Regional Specification'])\n",
    "                        if source_val: source = source_val\n",
    "\n",
    "                    # Phone (simple version from aria-label=call; keep as-is)\n",
    "                    phone_tag = detail_soup.find('a', href=True, attrs={'aria-label': re.compile(r'call', re.IGNORECASE)})\n",
    "                    if phone_tag:\n",
    "                        contact_number = norm(phone_tag.get_text())\n",
    "\n",
    "                    if transmission == \"N/A\":\n",
    "                        trans_val = get_detail(['Transmission', 'Transmission Type'])\n",
    "                        if trans_val: transmission = trans_val\n",
    "\n",
    "                    if doors == \"N/A\":\n",
    "                        doors_val = get_detail(['Number of doors', 'Doors'])\n",
    "                        if doors_val: doors = doors_val\n",
    "\n",
    "                    if kilometers == \"N/A\":\n",
    "                        km_val = get_detail(['Kilometers', 'KM', 'Mileage'])\n",
    "                        if km_val: kilometers = km_val\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\":warning: Detail fetch failed: {detail_url} -> {e}\")\n",
    "\n",
    "            # Prevent Excel auto-date for values like \"4/5\"\n",
    "            doors_for_csv = f\"'{doors}\" if re.match(r'^\\d+/\\d+$', doors) else doors\n",
    "\n",
    "            # Save row\n",
    "            dubizzle_cars['car_title'].append(title)\n",
    "            dubizzle_cars['location'].append(location)\n",
    "            dubizzle_cars['year'].append(year)\n",
    "            dubizzle_cars['price'].append(price)\n",
    "            dubizzle_cars['kilometers'].append(kilometers)\n",
    "            dubizzle_cars['transmission_type'].append(transmission)\n",
    "            dubizzle_cars['number_of_doors'].append(doors_for_csv)\n",
    "            dubizzle_cars['source'].append(source)\n",
    "            dubizzle_cars['model'].append(model)\n",
    "            dubizzle_cars['color'].append(color)\n",
    "            dubizzle_cars['contact_number'].append(contact_number)\n",
    "\n",
    "            print(f\"Title: {title[:40]} | KM: {kilometers} | Trans: {transmission} | Doors: {doors} | Source: {source}\")\n",
    "\n",
    "        current_page += 1\n",
    "        if current_page > MAX_PAGES:\n",
    "            print(\":white_check_mark: Reached MAX_PAGES.\")\n",
    "            break\n",
    "\n",
    "        time.sleep(POLITE_DELAY)\n",
    "\n",
    "    # Export\n",
    "    df = pd.DataFrame(dubizzle_cars)\n",
    "    df.to_csv(\"dubizzle_cars.csv\", index=False)\n",
    "    print(f\"\\n:white_check_mark: Scraping complete. {len(df)} car listings saved to 'dubizzle_cars.csv'\")\n",
    "\n",
    "    if len(df) > 0:\n",
    "        km_extracted = (df['kilometers'] != 'N/A').sum()\n",
    "        transmission_extracted = (df['transmission_type'] != 'N/A').sum()\n",
    "        doors_extracted = (df['number_of_doors'] != 'N/A').sum()\n",
    "        source_extracted = (df['source'] != 'N/A').sum()\n",
    "        print(f\"Kilometers extracted: {km_extracted}/{len(df)} ({km_extracted/len(df)*100:.1f}%)\")\n",
    "        print(f\"Transmission extracted: {transmission_extracted}/{len(df)} ({transmission_extracted/len(df)*100:.1f}%)\")\n",
    "        print(f\"Doors extracted: {doors_extracted}/{len(df)} ({doors_extracted/len(df)*100:.1f}%)\")\n",
    "        print(f\"Source extracted: {source_extracted}/{len(df)} ({source_extracted/len(df)*100:.1f}%)\")\n",
    "    else:\n",
    "        print(\"No data to analyze - no listings were scraped.\")\n",
    "\n",
    "    driver.quit()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad9f5b36",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
